from __future__ import print_function
import tensorflow as tf
import torch
import torch.nn as nn
import numpy as np
from utils.config import load_config, gan_from_config
import os
import sys
from models.dataset_networks import mnist_discriminator
import torch.nn.functional as F


a = np.array([[[[    -0.6518],
          [    -0.5568],
          [    -0.1169],
          [     0.3730],
          [     0.2129],
          [    -0.1546],
          [     1.3134],
          [     0.9435],
          [     0.9228],
          [     0.2360],
          [     1.8387],
          [    -0.4688],
          [     0.3767],
          [     1.5775],
          [    -1.8236],
          [    -0.8998],
          [    -2.4170],
          [    -0.2188],
          [     0.2006],
          [    -0.1688],
          [    -1.3323],
          [    -1.6641],
          [     2.2465],
          [     0.7902],
          [     0.2422],
          [    -0.5712],
          [    -0.9755],
          [     0.0934]],

         [[     0.2141],
          [    -0.9792],
          [    -0.2609],
          [     1.9752],
          [     0.1334],
          [     0.5181],
          [    -1.2961],
          [    -0.9977],
          [    -1.5497],
          [     1.5536],
          [    -0.1384],
          [     1.0346],
          [    -0.8814],
          [    -0.5397],
          [    -0.6791],
          [     0.2911],
          [     1.3165],
          [    -0.5303],
          [     1.0139],
          [     0.3200],
          [     1.2780],
          [    -0.4699],
          [    -0.3774],
          [     0.3213],
          [    -0.3891],
          [     0.3127],
          [    -0.9305],
          [     0.5565]],

         [[     2.0934],
          [    -1.4640],
          [    -1.5558],
          [    -0.2745],
          [     0.4220],
          [     0.4689],
          [    -1.0192],
          [     0.6357],
          [    -2.0442],
          [     0.9804],
          [     0.7503],
          [    -0.8744],
          [     1.3952],
          [    -1.2323],
          [     0.5896],
          [     0.0916],
          [     0.5064],
          [     0.2718],
          [     0.0049],
          [    -0.8102],
          [     1.3477],
          [    -0.8733],
          [    -1.2058],
          [     2.0895],
          [     0.6364],
          [     2.0419],
          [     1.0438],
          [    -0.1384]],

         [[     0.6745],
          [    -0.4955],
          [    -0.3495],
          [    -0.1332],
          [    -0.8491],
          [    -1.6305],
          [    -1.3487],
          [     1.5526],
          [     0.5459],
          [    -1.7570],
          [    -0.1233],
          [    -0.2092],
          [     0.7965],
          [     0.1747],
          [    -1.2960],
          [    -0.1338],
          [     0.1120],
          [     0.5159],
          [    -2.1280],
          [    -2.0415],
          [    -0.3886],
          [     1.4628],
          [    -1.5406],
          [    -0.5511],
          [     0.0933],
          [    -0.3732],
          [    -0.7203],
          [    -0.6587]],

         [[     0.5056],
          [    -0.7960],
          [    -0.2143],
          [     0.4198],
          [     1.3815],
          [     0.5113],
          [     0.5115],
          [     0.1052],
          [     0.0617],
          [     1.5710],
          [     0.4200],
          [    -2.6344],
          [     0.8563],
          [    -1.1209],
          [     0.6758],
          [    -1.1058],
          [    -1.4442],
          [    -0.0552],
          [     1.0535],
          [     0.6370],
          [     0.9860],
          [     0.9296],
          [    -0.6588],
          [    -0.0779],
          [     1.9263],
          [    -1.4557],
          [    -0.8951],
          [    -0.8600]],

         [[    -1.1484],
          [    -0.2605],
          [    -1.0641],
          [     0.1760],
          [     1.1538],
          [    -0.1896],
          [     0.3275],
          [     0.4956],
          [     1.4969],
          [     0.2139],
          [    -1.3145],
          [     0.0377],
          [     0.1059],
          [     0.9648],
          [     1.0090],
          [     0.8778],
          [    -1.5498],
          [    -0.3203],
          [    -1.0351],
          [     0.9085],
          [    -0.3081],
          [    -1.0944],
          [    -2.0864],
          [     1.0797],
          [     1.2947],
          [     1.7443],
          [     0.3004],
          [    -0.8711]],

         [[    -0.8201],
          [    -0.2320],
          [     1.7651],
          [    -1.2128],
          [     0.7499],
          [    -0.1281],
          [    -0.4483],
          [    -1.1276],
          [    -0.9374],
          [     0.7941],
          [    -0.5570],
          [     1.5238],
          [    -0.4454],
          [     0.5816],
          [     0.4117],
          [     0.2124],
          [     0.3929],
          [    -1.6531],
          [     1.3898],
          [     0.7637],
          [    -0.1117],
          [    -0.7616],
          [    -0.2062],
          [    -2.1659],
          [    -0.1970],
          [     1.1487],
          [     1.1998],
          [     0.0772]],

         [[    -0.9549],
          [    -0.2886],
          [    -0.6799],
          [     2.2315],
          [     0.7672],
          [     0.8986],
          [    -1.2726],
          [    -0.6784],
          [     0.3625],
          [    -0.3735],
          [    -0.5881],
          [     2.2367],
          [     0.6628],
          [    -0.4315],
          [    -0.2592],
          [     2.3831],
          [     1.2231],
          [     0.3763],
          [    -1.4160],
          [     0.0805],
          [    -0.3966],
          [     0.6657],
          [    -0.4027],
          [    -0.0109],
          [    -0.1935],
          [     0.9357],
          [    -0.5307],
          [     0.8568]],

         [[    -1.3657],
          [    -0.6227],
          [    -0.8005],
          [     0.0931],
          [     0.3668],
          [    -0.4912],
          [    -0.6234],
          [    -1.4628],
          [     1.2198],
          [    -1.5432],
          [     0.8436],
          [     0.4802],
          [    -0.7614],
          [    -0.0539],
          [     1.3033],
          [    -0.2658],
          [     0.9638],
          [    -0.2592],
          [    -0.5547],
          [    -1.4370],
          [    -0.0039],
          [     0.7002],
          [     0.6451],
          [    -1.3014],
          [     0.8282],
          [     0.7453],
          [    -0.1379],
          [    -0.7843]],

         [[    -0.5348],
          [     0.8773],
          [     1.8157],
          [     0.2418],
          [    -0.6238],
          [    -0.5772],
          [    -0.6326],
          [     0.9187],
          [    -0.5812],
          [     0.5792],
          [     0.3021],
          [    -0.4972],
          [     0.4336],
          [    -1.5911],
          [    -1.1370],
          [     0.2431],
          [     0.1889],
          [    -0.2977],
          [    -0.2320],
          [     0.8808],
          [     0.1932],
          [     1.0646],
          [     1.0382],
          [    -1.7714],
          [    -0.8946],
          [    -0.6186],
          [     1.0912],
          [     0.1143]],

         [[    -1.1182],
          [     0.4832],
          [    -1.2276],
          [    -2.0104],
          [     0.1759],
          [     0.1899],
          [     0.2098],
          [     1.4173],
          [    -0.5343],
          [     0.7635],
          [    -1.1894],
          [    -1.2910],
          [     0.3777],
          [    -1.5411],
          [    -1.0650],
          [     2.3439],
          [    -1.3115],
          [    -0.4521],
          [    -0.8448],
          [     1.2685],
          [     1.2435],
          [    -0.0584],
          [     0.0110],
          [     0.0266],
          [    -0.9352],
          [     1.4268],
          [     1.0922],
          [    -0.8915]],

         [[    -2.0436],
          [     0.8846],
          [     1.8423],
          [    -1.1675],
          [    -0.0567],
          [    -1.2527],
          [    -0.5149],
          [     1.4396],
          [     0.3062],
          [    -0.9969],
          [     1.4420],
          [    -1.0247],
          [     0.0483],
          [    -0.3391],
          [     0.7363],
          [     0.2259],
          [     1.7255],
          [     1.4207],
          [    -0.5877],
          [     0.7940],
          [    -0.9216],
          [     0.6338],
          [    -0.3339],
          [    -2.2623],
          [     0.7083],
          [     0.5414],
          [     0.7258],
          [    -0.3581]],

         [[    -0.4955],
          [     1.3165],
          [    -0.6092],
          [    -0.5884],
          [     0.5064],
          [     1.8440],
          [    -0.4754],
          [    -0.8804],
          [     1.8777],
          [     0.5677],
          [    -1.2607],
          [    -0.2223],
          [     0.3099],
          [     0.1114],
          [    -2.5917],
          [     0.3166],
          [    -0.6509],
          [     0.0340],
          [     1.1498],
          [    -1.8439],
          [    -0.1029],
          [     0.0512],
          [     0.3207],
          [     0.3813],
          [     0.5595],
          [     0.9467],
          [    -0.4034],
          [     0.3952]],

         [[    -1.0306],
          [     0.3646],
          [    -0.2615],
          [    -1.4741],
          [    -0.8684],
          [    -1.2987],
          [    -0.4027],
          [     1.6701],
          [    -0.0444],
          [     0.7606],
          [     0.8793],
          [    -1.4621],
          [     0.6436],
          [    -0.3440],
          [     0.7044],
          [    -0.6944],
          [    -1.1323],
          [    -2.5410],
          [     0.0736],
          [    -0.2427],
          [    -0.8196],
          [     1.4301],
          [    -1.0702],
          [    -0.0781],
          [    -0.4476],
          [     0.6715],
          [    -0.4305],
          [    -0.7768]],

         [[     0.3177],
          [    -1.7826],
          [     0.3768],
          [     0.8682],
          [    -1.3333],
          [     2.5755],
          [     0.4866],
          [     1.9621],
          [    -1.0738],
          [    -0.7180],
          [    -0.2922],
          [    -2.2184],
          [    -0.1888],
          [    -0.9822],
          [    -0.7915],
          [     0.7656],
          [    -0.4609],
          [    -0.0882],
          [     1.1344],
          [    -0.6066],
          [    -0.7355],
          [     0.8452],
          [     0.6254],
          [    -0.6768],
          [    -1.7980],
          [    -1.0041],
          [     0.4046],
          [    -3.1939]],

         [[     0.5238],
          [     0.9702],
          [    -1.1174],
          [    -0.8044],
          [     0.1220],
          [    -0.3484],
          [    -0.1533],
          [     0.4545],
          [    -1.1474],
          [     0.5170],
          [     0.4942],
          [    -1.3668],
          [     0.2842],
          [    -0.3790],
          [    -0.1752],
          [    -0.5694],
          [    -0.8403],
          [     0.4370],
          [     0.0178],
          [    -0.5272],
          [     0.3078],
          [     1.0253],
          [    -0.2594],
          [    -0.9330],
          [     0.0473],
          [     0.8507],
          [    -1.1869],
          [     0.1336]],

         [[    -0.5248],
          [    -0.8706],
          [    -1.2430],
          [    -0.8287],
          [    -0.6732],
          [    -0.0986],
          [     0.5055],
          [     0.1431],
          [    -0.3152],
          [    -0.1023],
          [     1.1680],
          [    -0.2850],
          [    -0.1344],
          [     0.0359],
          [    -1.3128],
          [    -0.2806],
          [     0.4091],
          [    -0.7272],
          [     0.1966],
          [     0.5976],
          [     1.1983],
          [     0.1625],
          [    -1.0561],
          [     0.0890],
          [     0.4293],
          [     0.4824],
          [    -0.0891],
          [     0.9100]],

         [[     2.3598],
          [     0.0510],
          [     1.7711],
          [     1.9189],
          [    -0.2784],
          [     0.7944],
          [     0.0558],
          [     0.9705],
          [     0.8755],
          [    -0.4578],
          [    -1.5153],
          [     0.1780],
          [     0.9600],
          [    -0.4812],
          [    -1.3125],
          [    -0.4158],
          [     1.0678],
          [    -0.4553],
          [     1.2148],
          [    -0.3276],
          [    -0.4647],
          [     0.7203],
          [     1.1515],
          [     0.5005],
          [     0.2683],
          [    -0.1595],
          [    -0.4550],
          [    -0.9067]],

         [[    -1.6097],
          [     1.2267],
          [    -1.5842],
          [    -1.2772],
          [     0.0970],
          [    -0.3604],
          [     0.0933],
          [    -0.8221],
          [    -1.1036],
          [    -0.1087],
          [     0.1814],
          [    -0.6723],
          [     0.1670],
          [    -0.1687],
          [     0.3168],
          [     0.9288],
          [     2.4599],
          [     0.1544],
          [     0.8072],
          [    -0.3708],
          [     1.2773],
          [     0.0011],
          [     0.8974],
          [     0.9035],
          [    -0.0730],
          [     0.7483],
          [     1.0010],
          [     0.5563]],

         [[     0.6038],
          [    -0.7786],
          [     0.1388],
          [     1.3306],
          [     0.6053],
          [     0.2100],
          [     0.0460],
          [     1.2422],
          [     0.1174],
          [    -1.7905],
          [     0.4565],
          [     1.1372],
          [     1.5430],
          [     0.3903],
          [     0.3468],
          [     1.5939],
          [    -0.8289],
          [     2.3392],
          [    -0.6032],
          [     1.2936],
          [    -0.1592],
          [    -0.2877],
          [    -0.1183],
          [     0.9774],
          [     2.0825],
          [     0.5975],
          [    -0.8478],
          [     1.4815]],

         [[     0.6131],
          [     0.5315],
          [    -0.0200],
          [    -0.6916],
          [    -0.5569],
          [    -0.4277],
          [    -0.4551],
          [    -0.4733],
          [     0.1768],
          [    -0.5957],
          [    -0.5184],
          [     0.1944],
          [     0.2044],
          [     0.3010],
          [     0.3272],
          [    -0.6319],
          [     1.1601],
          [     0.4550],
          [    -2.7714],
          [    -0.9938],
          [    -0.0780],
          [    -1.0609],
          [     0.7627],
          [     0.9715],
          [    -0.0319],
          [    -0.7783],
          [     0.6359],
          [    -1.1538]],

         [[     0.2451],
          [     2.1502],
          [    -0.5744],
          [     2.2640],
          [    -1.5365],
          [    -2.0181],
          [     0.4167],
          [    -0.5362],
          [     0.0259],
          [    -0.3626],
          [     2.1052],
          [     1.6193],
          [    -0.4295],
          [    -0.2608],
          [    -0.3415],
          [    -0.6554],
          [    -0.6828],
          [    -0.9294],
          [    -0.1467],
          [     0.5854],
          [     1.1552],
          [     0.0939],
          [    -0.6394],
          [     0.9883],
          [     1.3007],
          [    -0.7866],
          [     1.3072],
          [    -0.2075]],

         [[    -0.0095],
          [     1.0589],
          [     1.1904],
          [     0.9842],
          [     0.3227],
          [     1.1393],
          [     1.4502],
          [     0.5330],
          [     1.2158],
          [    -0.2449],
          [     1.1330],
          [    -0.2971],
          [    -1.5070],
          [    -0.4403],
          [    -1.0657],
          [     1.6532],
          [    -1.9896],
          [     0.7655],
          [    -0.3745],
          [     0.5204],
          [     0.3971],
          [    -0.6121],
          [    -0.9306],
          [     0.4250],
          [    -0.6773],
          [     0.4808],
          [    -1.3184],
          [     0.8994]],

         [[     0.8570],
          [     0.7059],
          [     1.9673],
          [    -1.4097],
          [    -0.6713],
          [    -0.6437],
          [     1.4603],
          [    -0.1377],
          [    -0.7487],
          [    -0.1814],
          [    -0.3075],
          [    -0.5932],
          [     0.2364],
          [    -0.3203],
          [    -0.6808],
          [    -0.2772],
          [    -0.4969],
          [     0.2728],
          [    -0.2305],
          [    -0.7861],
          [     0.3738],
          [    -0.2216],
          [    -1.0138],
          [    -0.4630],
          [    -0.2303],
          [    -2.0204],
          [    -1.3584],
          [     1.1808]],

         [[     0.4447],
          [    -0.4745],
          [     0.6287],
          [    -0.2150],
          [    -1.0069],
          [    -0.9526],
          [    -0.9938],
          [     0.3576],
          [     1.6348],
          [    -0.1844],
          [     0.3240],
          [     1.2908],
          [    -0.8190],
          [    -0.5835],
          [    -0.9564],
          [    -1.9430],
          [     1.1476],
          [    -0.2029],
          [    -1.3417],
          [    -0.3283],
          [    -0.0787],
          [     1.5096],
          [     0.2726],
          [    -0.4138],
          [    -0.5104],
          [     0.3040],
          [    -0.6222],
          [     0.0947]],

         [[     0.5095],
          [    -0.6237],
          [     0.6275],
          [     0.3568],
          [    -2.4521],
          [     0.2825],
          [     0.9017],
          [    -0.3352],
          [     0.4298],
          [     0.9766],
          [     1.0025],
          [    -1.9364],
          [    -0.0951],
          [     0.8904],
          [     1.2975],
          [     1.7271],
          [    -1.7470],
          [     0.0013],
          [     0.2356],
          [    -1.9637],
          [    -0.8361],
          [     0.1084],
          [     0.6764],
          [    -0.8780],
          [    -0.7599],
          [    -0.2047],
          [    -1.0027],
          [     0.4846]],

         [[    -1.5155],
          [    -0.0346],
          [    -0.8485],
          [    -0.1038],
          [     0.9931],
          [    -0.1428],
          [    -0.0086],
          [    -0.7837],
          [    -1.0137],
          [     0.3629],
          [    -1.2614],
          [     0.9043],
          [     1.3663],
          [     1.9109],
          [     2.4187],
          [     0.0309],
          [    -1.1370],
          [     0.8715],
          [     1.9613],
          [     0.0679],
          [     1.2758],
          [    -0.5272],
          [     0.7944],
          [     1.2873],
          [     0.3750],
          [     0.9556],
          [     0.0098],
          [    -1.6206]],

         [[    -0.3734],
          [     1.2842],
          [    -0.4807],
          [    -0.4606],
          [     0.9271],
          [    -0.3309],
          [    -1.7871],
          [     1.8527],
          [     0.7273],
          [    -0.4869],
          [    -0.6217],
          [    -0.2586],
          [    -1.4574],
          [    -0.7142],
          [     0.1539],
          [     1.4142],
          [    -1.2017],
          [    -1.2975],
          [    -0.3347],
          [     0.5845],
          [    -1.1240],
          [    -0.2931],
          [     1.3203],
          [    -0.3399],
          [     2.0068],
          [     0.4764],
          [     1.1817],
          [     0.1443]]],


        [[[     0.5022],
          [    -0.6847],
          [     0.4887],
          [    -0.4941],
          [     0.1721],
          [     0.6659],
          [    -0.2814],
          [    -0.4488],
          [    -0.6885],
          [     0.1148],
          [     1.7529],
          [    -0.6277],
          [    -0.3605],
          [    -0.4219],
          [    -1.6735],
          [     0.8368],
          [     2.3233],
          [    -0.8442],
          [    -3.0944],
          [     1.2241],
          [    -0.2044],
          [    -0.1439],
          [    -0.3325],
          [     0.8440],
          [    -0.3674],
          [     0.8953],
          [     1.7003],
          [     0.3327]],

         [[    -0.4032],
          [     0.2877],
          [    -0.6120],
          [     0.8644],
          [     3.0013],
          [     0.6424],
          [     0.5255],
          [     0.1451],
          [    -0.5394],
          [     0.3644],
          [     0.0443],
          [     2.3904],
          [    -0.1457],
          [     1.6658],
          [    -0.6123],
          [     1.6015],
          [     0.6011],
          [    -0.0240],
          [    -0.8690],
          [    -2.0268],
          [    -0.1657],
          [     0.0977],
          [     1.1017],
          [    -0.2824],
          [    -0.6273],
          [     0.0108],
          [    -1.1790],
          [    -0.8206]],

         [[     1.5999],
          [    -0.7001],
          [    -1.1369],
          [     0.0374],
          [    -2.4276],
          [     2.3246],
          [    -0.4656],
          [    -0.8939],
          [    -0.0069],
          [    -0.7077],
          [     0.4113],
          [     0.5583],
          [    -0.1959],
          [    -0.3375],
          [     0.1768],
          [    -0.0135],
          [    -2.0082],
          [    -0.1629],
          [     0.3854],
          [    -0.5906],
          [     0.4400],
          [    -1.8655],
          [    -0.5122],
          [    -0.0750],
          [    -0.7918],
          [    -2.0301],
          [     1.8129],
          [     0.2977]],

         [[     0.1254],
          [    -0.4632],
          [     1.5596],
          [    -1.5442],
          [     0.2786],
          [    -1.1244],
          [     0.9955],
          [     0.2454],
          [     0.8541],
          [    -0.5974],
          [    -0.1139],
          [    -0.2200],
          [     0.6424],
          [    -0.4810],
          [     0.2935],
          [     1.9275],
          [    -0.3286],
          [     0.5669],
          [    -0.0048],
          [     2.3601],
          [    -0.7724],
          [     1.0549],
          [    -1.0497],
          [    -0.6117],
          [    -1.7596],
          [     0.7217],
          [     0.9658],
          [    -0.0291]],

         [[     0.7999],
          [     0.0686],
          [     0.9798],
          [    -1.3732],
          [     0.4469],
          [     0.0712],
          [     0.9498],
          [    -1.4908],
          [     0.7882],
          [    -0.9382],
          [    -2.5061],
          [     0.0001],
          [    -0.8202],
          [     0.8248],
          [    -1.0759],
          [     0.1401],
          [     0.0461],
          [     0.6790],
          [     0.9929],
          [    -0.1633],
          [    -1.5718],
          [    -0.3422],
          [     0.9183],
          [    -0.5428],
          [     1.8161],
          [    -0.9846],
          [     1.2106],
          [    -0.0352]],

         [[     0.7635],
          [    -0.9085],
          [    -0.3479],
          [    -0.2643],
          [     0.8966],
          [    -1.0784],
          [    -0.0099],
          [    -0.7622],
          [    -1.6818],
          [    -0.7237],
          [    -0.7243],
          [     1.7788],
          [     0.1498],
          [     1.3019],
          [    -0.4261],
          [    -0.2113],
          [    -0.9630],
          [    -0.3205],
          [    -0.9053],
          [     0.8055],
          [    -1.4502],
          [     0.5750],
          [    -0.2357],
          [    -0.6407],
          [    -0.7706],
          [     0.0351],
          [     1.9236],
          [    -2.4683]],

         [[    -0.1449],
          [     2.6494],
          [    -0.3137],
          [    -0.0625],
          [    -0.4854],
          [     0.4519],
          [     0.3228],
          [     0.1750],
          [     0.3538],
          [    -0.3209],
          [    -0.0793],
          [    -0.0064],
          [    -1.1074],
          [    -0.5511],
          [    -0.9119],
          [     0.4284],
          [     0.3899],
          [     1.1227],
          [     2.7221],
          [     0.6909],
          [    -0.8076],
          [    -1.2630],
          [     0.5174],
          [    -1.4824],
          [    -0.5426],
          [    -0.3237],
          [    -0.6147],
          [    -0.6507]],

         [[     0.2683],
          [    -0.4266],
          [     1.4934],
          [     0.5326],
          [     1.0991],
          [     0.5370],
          [    -0.2282],
          [     0.8632],
          [     2.0619],
          [     0.7471],
          [    -1.0567],
          [    -0.7570],
          [     0.3382],
          [     0.4694],
          [    -1.1717],
          [     0.4472],
          [     0.4004],
          [    -0.4112],
          [    -1.3889],
          [     1.1749],
          [     0.7835],
          [     0.5183],
          [     0.0863],
          [    -0.7373],
          [    -2.6041],
          [    -1.1956],
          [    -0.0697],
          [     0.7994]],

         [[    -1.3802],
          [     0.5602],
          [     0.0292],
          [    -0.5932],
          [    -1.8357],
          [     0.6275],
          [     0.7073],
          [     1.0595],
          [    -0.3947],
          [    -0.9876],
          [    -0.5229],
          [    -0.2463],
          [    -0.9356],
          [    -0.2181],
          [    -1.5517],
          [     0.2249],
          [     0.9582],
          [    -0.3779],
          [    -0.1372],
          [    -2.6344],
          [    -1.2215],
          [     1.4811],
          [     0.0929],
          [    -0.5001],
          [     2.1328],
          [    -0.7757],
          [    -0.3931],
          [     0.7223]],

         [[     1.5915],
          [     0.1040],
          [     1.6053],
          [     0.1012],
          [     1.0746],
          [    -0.9207],
          [     0.5756],
          [     1.5009],
          [     0.8490],
          [     1.4655],
          [     2.3360],
          [     0.5603],
          [    -0.9553],
          [    -1.0648],
          [     2.1213],
          [    -0.7923],
          [     0.1514],
          [     0.6108],
          [    -0.4633],
          [     0.3271],
          [    -0.2645],
          [     1.3381],
          [    -0.4667],
          [    -0.8319],
          [     0.1250],
          [     0.2840],
          [     0.2901],
          [     1.0327]],

         [[     0.1994],
          [    -0.6037],
          [     0.7069],
          [     0.3475],
          [     0.4459],
          [     1.8293],
          [     0.8980],
          [    -0.1905],
          [    -1.5058],
          [     1.4733],
          [    -0.1780],
          [     0.8476],
          [     0.8573],
          [     0.1555],
          [    -0.8668],
          [    -0.2989],
          [    -0.4938],
          [    -1.0465],
          [     2.8233],
          [     0.5512],
          [    -0.2622],
          [     2.7655],
          [    -0.8673],
          [     0.9919],
          [    -0.8283],
          [     0.3839],
          [    -1.0484],
          [     0.0952]],

         [[    -0.6708],
          [    -1.2649],
          [    -0.9093],
          [    -0.0160],
          [    -0.0339],
          [     0.7886],
          [     3.0207],
          [    -0.4499],
          [     1.9378],
          [     0.5648],
          [     0.5159],
          [     0.1541],
          [     1.6212],
          [     0.7246],
          [    -1.3616],
          [    -2.4473],
          [     0.8785],
          [    -1.0087],
          [     0.1846],
          [    -0.7552],
          [    -0.0812],
          [    -0.1594],
          [     1.3856],
          [     0.4502],
          [     0.6058],
          [    -0.2051],
          [     0.1420],
          [     3.2207]],

         [[     1.3624],
          [     0.2908],
          [    -0.1673],
          [    -1.0931],
          [    -0.0545],
          [     0.1695],
          [     1.8332],
          [     0.3996],
          [    -0.6044],
          [    -3.1335],
          [     0.6139],
          [    -0.1657],
          [     0.3568],
          [     0.2266],
          [    -0.8648],
          [     0.2837],
          [     0.3055],
          [    -0.0481],
          [    -0.9763],
          [    -1.2733],
          [     0.2830],
          [     0.2195],
          [     1.3664],
          [    -1.5267],
          [     0.7232],
          [    -0.7381],
          [    -0.0087],
          [     0.6402]],

         [[     0.5559],
          [    -0.4569],
          [     0.8084],
          [     0.8889],
          [    -0.0731],
          [    -1.5974],
          [     0.1243],
          [     0.1459],
          [    -0.7158],
          [     0.9030],
          [    -0.2752],
          [     1.1032],
          [    -0.3891],
          [     0.7920],
          [    -2.9707],
          [    -1.1638],
          [     2.1464],
          [     0.5370],
          [     0.1594],
          [     1.1429],
          [     0.0308],
          [     0.1062],
          [     0.0419],
          [     0.3882],
          [    -1.2273],
          [    -0.1426],
          [    -0.1603],
          [     0.5243]],

         [[     0.1643],
          [    -1.1851],
          [     1.4051],
          [    -0.9372],
          [     0.6051],
          [    -0.3688],
          [    -0.0623],
          [     0.3047],
          [     0.3108],
          [     1.2821],
          [    -1.8137],
          [    -0.7684],
          [     0.9359],
          [    -0.3738],
          [     1.5358],
          [     0.3790],
          [    -0.6230],
          [    -0.7924],
          [     0.7942],
          [    -1.8485],
          [    -0.0358],
          [    -1.8729],
          [     1.0159],
          [     1.3147],
          [     0.1169],
          [    -0.1867],
          [    -0.5680],
          [    -1.5828]],

         [[     0.0629],
          [     0.0231],
          [    -0.9180],
          [    -0.1891],
          [     0.9482],
          [    -0.8405],
          [     0.6047],
          [    -1.2550],
          [    -1.3100],
          [    -0.8825],
          [     0.9514],
          [     2.1662],
          [    -0.6430],
          [     0.8224],
          [    -0.3456],
          [    -0.1832],
          [    -1.0133],
          [    -0.4741],
          [    -0.7542],
          [    -0.3550],
          [    -0.4415],
          [     0.5345],
          [     0.2366],
          [     0.5124],
          [     0.2154],
          [    -2.1643],
          [    -1.7486],
          [     0.3061]],

         [[     0.3728],
          [    -0.0125],
          [     0.6459],
          [     1.8221],
          [    -0.7708],
          [    -0.6126],
          [     0.9466],
          [     2.3020],
          [     0.3665],
          [     0.4202],
          [    -0.6217],
          [    -1.8014],
          [    -0.5021],
          [     0.7644],
          [     0.0265],
          [    -0.5574],
          [     0.1020],
          [     0.1294],
          [    -0.0528],
          [    -0.2947],
          [     0.0964],
          [     0.4771],
          [     1.1478],
          [    -0.6846],
          [     1.1447],
          [     1.6250],
          [    -0.2930],
          [     2.1886]],

         [[     0.1040],
          [     2.2632],
          [     1.5741],
          [     0.7929],
          [     1.0915],
          [    -2.5163],
          [    -1.4904],
          [     0.0444],
          [    -0.1641],
          [    -0.0158],
          [     0.7541],
          [    -2.8893],
          [     0.8587],
          [     0.0994],
          [    -1.9896],
          [    -0.1790],
          [     0.2448],
          [    -0.6640],
          [     2.6264],
          [    -1.3014],
          [     1.2786],
          [     1.1887],
          [     0.7585],
          [    -0.1261],
          [    -1.5158],
          [    -0.9400],
          [    -0.3952],
          [    -1.5792]],

         [[    -0.1713],
          [     0.7987],
          [     0.7515],
          [     0.3730],
          [    -2.4092],
          [    -0.1615],
          [    -0.5615],
          [    -0.7439],
          [    -1.7301],
          [    -0.9185],
          [     1.5777],
          [     1.0333],
          [    -1.4365],
          [     0.5713],
          [    -0.5033],
          [    -0.6002],
          [    -0.2725],
          [     1.1221],
          [     0.5590],
          [    -0.2480],
          [    -0.1963],
          [    -0.8556],
          [     0.0506],
          [    -0.0915],
          [     2.5916],
          [    -0.2790],
          [     1.3634],
          [    -0.9289]],

         [[     0.8846],
          [    -2.1789],
          [     2.4418],
          [     0.2583],
          [    -0.2846],
          [    -1.7933],
          [     0.2801],
          [    -1.1849],
          [    -0.4943],
          [     0.0595],
          [     2.9884],
          [    -0.4770],
          [    -0.1859],
          [     0.9251],
          [    -0.1575],
          [    -1.4617],
          [    -0.5379],
          [    -1.9584],
          [     0.8319],
          [    -0.2080],
          [     1.8873],
          [    -1.0774],
          [     0.3905],
          [    -0.7882],
          [    -0.2575],
          [     1.1922],
          [     0.4454],
          [     0.2616]],

         [[     1.6572],
          [    -0.4215],
          [    -0.4911],
          [    -0.3500],
          [     0.2843],
          [     1.7064],
          [    -1.9014],
          [    -1.5007],
          [     0.3876],
          [     0.2695],
          [     1.3923],
          [    -0.3946],
          [     0.6478],
          [    -0.4493],
          [     1.9942],
          [    -1.6036],
          [     0.8000],
          [    -0.5521],
          [     0.5819],
          [     0.9893],
          [    -0.7489],
          [     1.2004],
          [     1.2282],
          [     1.8128],
          [     0.8978],
          [     1.0693],
          [     1.0111],
          [     0.3342]],

         [[    -1.4679],
          [    -0.0328],
          [     1.8889],
          [    -0.5320],
          [    -0.4655],
          [     0.9305],
          [     1.5493],
          [    -0.5769],
          [    -0.4139],
          [    -0.5577],
          [    -1.2820],
          [    -0.5325],
          [     2.3900],
          [     0.4221],
          [     0.0070],
          [    -0.6427],
          [     0.9217],
          [    -2.0757],
          [     1.0045],
          [     2.4778],
          [    -0.1512],
          [    -0.0192],
          [    -1.8032],
          [     0.4045],
          [    -0.2001],
          [     0.9180],
          [    -0.6706],
          [    -0.2189]],

         [[     1.1122],
          [    -0.2174],
          [    -0.6389],
          [     0.1529],
          [    -0.3746],
          [    -1.2358],
          [     1.0074],
          [     1.9802],
          [     0.2608],
          [     0.2176],
          [    -1.2680],
          [    -0.2603],
          [     0.1322],
          [    -0.8080],
          [     0.1003],
          [    -0.3774],
          [    -0.7543],
          [    -0.9033],
          [     0.8794],
          [    -0.4721],
          [     1.0177],
          [     0.1610],
          [     0.4352],
          [    -1.1109],
          [     1.4236],
          [    -1.9548],
          [    -0.9031],
          [    -0.5795]],

         [[     0.5974],
          [    -0.5016],
          [     1.0454],
          [    -0.1440],
          [     1.3196],
          [     0.4310],
          [     0.8128],
          [     0.8228],
          [    -0.2913],
          [    -1.2851],
          [     0.3725],
          [     0.1935],
          [     0.5801],
          [     0.5570],
          [    -0.3166],
          [    -1.1453],
          [     0.4922],
          [    -0.3596],
          [     2.0274],
          [     0.7636],
          [    -0.6158],
          [     1.2087],
          [    -0.1356],
          [    -3.1344],
          [    -0.3632],
          [     0.6131],
          [    -0.5635],
          [    -0.1052]],

         [[     0.2546],
          [    -1.4674],
          [    -0.0471],
          [     3.0200],
          [     1.5702],
          [     1.0619],
          [    -0.4992],
          [    -0.9985],
          [     0.3522],
          [    -0.2896],
          [     0.5829],
          [     1.0914],
          [    -0.2849],
          [     1.3895],
          [     0.2811],
          [    -0.7580],
          [    -2.0355],
          [     1.0093],
          [     0.6041],
          [    -0.0840],
          [    -1.1548],
          [    -1.1814],
          [     0.4811],
          [     1.0387],
          [     0.3082],
          [    -0.5706],
          [    -0.3290],
          [    -0.9276]],

         [[    -0.4900],
          [    -1.1729],
          [     1.2472],
          [    -0.1842],
          [     0.1734],
          [    -0.4711],
          [     0.4339],
          [     0.3459],
          [     0.2736],
          [    -0.3051],
          [     0.4779],
          [    -2.0159],
          [    -0.6457],
          [    -0.6071],
          [    -1.2026],
          [     0.4227],
          [     0.4159],
          [     0.9350],
          [     0.9950],
          [    -0.6628],
          [    -0.6628],
          [    -0.9218],
          [    -1.3781],
          [     1.8357],
          [    -0.0381],
          [    -0.2849],
          [     0.7300],
          [     0.5840]],

         [[     0.4067],
          [    -0.5864],
          [    -0.0574],
          [     1.2139],
          [     1.1142],
          [    -0.2530],
          [    -1.6095],
          [    -1.1851],
          [     1.0730],
          [     0.1760],
          [    -2.4965],
          [     0.2917],
          [     1.2354],
          [     0.3044],
          [     0.1364],
          [     0.7950],
          [     0.3024],
          [    -0.1730],
          [     1.8727],
          [     0.0449],
          [    -0.4071],
          [     0.0795],
          [    -1.4227],
          [     0.0235],
          [     0.6665],
          [    -1.6089],
          [    -0.2037],
          [     1.0970]],

         [[    -1.3668],
          [     0.8092],
          [    -0.9060],
          [    -0.3554],
          [    -0.4872],
          [     0.6546],
          [    -0.5382],
          [     0.2484],
          [    -2.5073],
          [    -0.2824],
          [    -0.0584],
          [     0.5933],
          [     0.3786],
          [     0.1208],
          [    -0.3006],
          [     1.4531],
          [     0.3669],
          [     0.0570],
          [     0.5025],
          [    -1.0857],
          [    -1.4375],
          [     0.4770],
          [    -0.1803],
          [    -0.4409],
          [     0.2532],
          [    -0.3240],
          [    -1.2157],
          [     1.4758]]]])

initial_pyt = torch.from_numpy(a)



def tf_dis_inference():
    # a = np.random.randn(2,28,28,1)
    # tf_initial = tf.convert_to_tensor(a, dtype=tf.float32)  
    # mnist_discriminator(tf_initial)

    test_mode = True
    ckpt_path = "experiments/cfgs/gans/mnist.yml"
    cfg = load_config(ckpt_path)
    gan = gan_from_config(cfg, test_mode)

    sess = gan.sess
    gan.initialize_uninitialized()
    gan.load_discriminator(ckpt_path="output/gans/mnist")


    gan._build()

    
    disc_output = gan.sess.run(
        [gan.disc_real]
    )
    
    return disc_output

def l2normalise(v, eps=1e-12):
    return v / (torch.sum(v ** 2) ** 0.5 + eps)

def spectral_norm(w,u,num_iters = 1):

    w_shape = w.shape
    w = torch.reshape(w,(-1,w_shape[-1]))
    u_hat = u
    v_hat = None
    w_trans = torch.transpose(w,0,1)
    for _ in range(num_iters):
        v_ = torch.matmul(u_hat,w_trans)
        v_hat = l2normalise(v_) #(1,k*k*in_channels)

        u_ = torch.matmul(v_hat,w) 
        u_hat = l2normalise(u_) #(1,out_channels)
        u_hat_trans = torch.transpose(u_hat,0,1) #(out,1)
    
    sigma = torch.squeeze(torch.matmul(torch.matmul(v_hat,w),u_hat_trans)) #(scalar) = [1] dimension
    w_norm = w/sigma

    w_norm = torch.reshape(w_norm,w_shape) #(k,k,in,out)
    return w_norm
    


class Myconv(nn.Conv2d):
    def __init__(self, in_channels, out_channels, kernel_size, stride=1,padding=0, dilation=1, groups=1, bias=True,num_iters = 1):
        nn.Conv2d.__init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)
        self.u = nn.Parameter(torch.zeros((1,out_channels)),requires_grad = False)


    def forward(self, x):

        w = self.weight.permute(2,3,1,0) #(k,k,in,out)
        w_norm = spectral_norm(w,self.u)
        w_final = w_norm.permute(3,2,0,1)
        self.weight = nn.Parameter(w_final)

        return F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)



class Mylinear(nn.Linear):
    def __init__(self,in_features, out_features, bias=True):
        nn.Linear.__init__(self,in_features, out_features, bias)
        self.u = nn.Parameter(torch.zeros((1,out_features)),requires_grad = False)


    def forward(self,x):

        w = self.weight.permute(1,0) #(in,out)
        w_norm = spectral_norm(w,self.u)
        w_final = w_norm.permute(1,0) #(out,in)
        self.weight = nn.Parameter(w_final)
        return F.linear(x,self.weight,self.bias)





class Discriminator(nn.Module):
    def __init__(self):
        net_dim = 64
        super(Discriminator,self).__init__()
        self.conv0 = Myconv(1,net_dim,5,2)
        self.lrelu = nn.LeakyReLU(negative_slope=0.2)
        self.conv1 = Myconv(net_dim,2*net_dim,5,2)
        self.conv2 = Myconv(2*net_dim,4*net_dim,5,2)
        self.linear = Mylinear(4096,1)

    def forward(self,x):
        net_dim = 64
        x = torch.nn.functional.pad(x, (1,2,1,2), mode='constant', value=0)
        output = self.conv0(x)
        output = self.lrelu(output)
        print(output.shape)
        output = torch.nn.functional.pad(output, (1,2,1,2), mode='constant', value=0)
        output = self.conv1(output)
        output = self.lrelu(output)
        print(output.shape)
        output = torch.nn.functional.pad(output, (2,2,2,2), mode='constant', value=0)
        output = self.conv2(output)
        output = self.lrelu(output)
        print(output.shape)
        output = output.permute(0,2,3,1)
        output = torch.reshape(output,(output.shape[0],4*4*4*net_dim))
        print(output.shape)
        output = self.linear(output) #(N,1)
        print(output.shape)
        print(torch.squeeze(output).shape)

        return torch.squeeze(output) #(N)


def p_vars(path):
    tf_path = os.path.abspath(path)  # Path to our TensorFlow checkpoint
    tf_vars = tf.train.list_variables(tf_path)
    return (tf_vars,tf_path)


def load_dis_pyt_weights():

    (init_vars,tf_path) = p_vars('output/gans/mnist/GAN.model-200000')

    model = Discriminator()

    tf_vars = []

    for name, shape in init_vars:
        # print("Loading TF weight {} with shape {}".format(name, shape))
        array = tf.train.load_variable(tf_path, name)
        tf_vars.append((name, array))

    for name, array in tf_vars:

        if name[:13] == "Discriminator":
            name = name[14:].split('/')

            pointer = model

            l = name
            print(l)
            if len(l) == 3:
                continue


            if l[0] == "conv0" or l[0] == "conv1" or l[0] == "conv2":
                pointer = getattr(pointer,l[0])
                if l[1] == "biases":
                    pointer = getattr(pointer,"bias")
                elif l[1] == "w":
                    pointer = getattr(pointer,"weight")
                elif l[1] == "u":
                    pointer = getattr(pointer,"u")
            if l[0] == "linear":
                pointer = getattr(pointer,l[0])
                if l[1] == "W":
                    pointer = getattr(pointer,"weight")
                elif l[1] == "bias":
                    pointer = getattr(pointer,"bias")
                elif l[1] == "u":
                    pointer = getattr(pointer,"u")

            # print(array,array.shape)

            # print("Initialize PyTorch weight {}".format(name))
            if (l[1] == "W" or l[1] == "w") and l[0] != "linear":
                temp_tensor = torch.from_numpy(array)

                temp_tensor = temp_tensor.permute(3,2,0,1)
                pointer.data = temp_tensor 
            elif l[0] == "linear" and l[1] == "W":
                temp_tensor = torch.from_numpy(array)
                temp_tensor = temp_tensor.permute(1,0)
                pointer.data = temp_tensor 
            else:

                pointer.data = torch.from_numpy(array)

    return model #loaded model returned remember to put to eval mode before inference



if __name__ == '__main__':
    print(tf_dis_inference())
    model = load_dis_pyt_weights()
    model = model.eval()
    initial_pyt = initial_pyt.permute(0,3,1,2)
    initial_pyt = initial_pyt.to(torch.float32)
    print(model(initial_pyt))